<!DOCTYPE html><html class="default" lang="en"><head><meta charSet="utf-8"/><meta http-equiv="x-ua-compatible" content="IE=edge"/><title>@wllama/wllama</title><meta name="description" content="Documentation for @wllama/wllama"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="stylesheet" href="assets/style.css"/><link rel="stylesheet" href="assets/highlight.css"/><script defer src="assets/main.js"></script><script async src="assets/icons.js" id="tsd-icons-script"></script><script async src="assets/search.js" id="tsd-search-script"></script><script async src="assets/navigation.js" id="tsd-nav-script"></script></head><body><script>document.documentElement.dataset.theme = localStorage.getItem("tsd-theme") || "os";document.body.style.display="none";setTimeout(() => app?app.showPage():document.body.style.removeProperty("display"),500)</script><header class="tsd-page-toolbar"><div class="tsd-toolbar-contents container"><div class="table-cell" id="tsd-search" data-base="."><div class="field"><label for="tsd-search-field" class="tsd-widget tsd-toolbar-icon search no-caption"><svg width="16" height="16" viewBox="0 0 16 16" fill="none"><use href="assets/icons.svg#icon-search"></use></svg></label><input type="text" id="tsd-search-field" aria-label="Search"/></div><div class="field"><div id="tsd-toolbar-links"></div></div><ul class="results"><li class="state loading">Preparing search index...</li><li class="state failure">The search index is not available</li></ul><a href="index.html" class="title">@wllama/wllama</a></div><div class="table-cell" id="tsd-widgets"><a href="#" class="tsd-widget tsd-toolbar-icon menu no-caption" data-toggle="menu" aria-label="Menu"><svg width="16" height="16" viewBox="0 0 16 16" fill="none"><use href="assets/icons.svg#icon-menu"></use></svg></a></div></div></header><div class="container container-main"><div class="col-content"><div class="tsd-page-title"><h2>@wllama/wllama</h2></div><div class="tsd-panel tsd-typography"><a id="md:wllama---wasm-binding-for-llamacpp" class="tsd-anchor"></a><h1><a href="#md:wllama---wasm-binding-for-llamacpp">wllama - Wasm binding for llama.cpp</a></h1><p><img src="./README_banner.png" alt=""></p>
<p>Another WebAssembly binding for <a href="https://github.com/ggerganov/llama.cpp">llama.cpp</a>. Inspired by <a href="https://github.com/tangledgroup/llama-cpp-wasm">tangledgroup/llama-cpp-wasm</a>, but unlike it, <strong>Wllama</strong> aims to supports <strong>low-level API</strong> like (de)tokenization, embeddings,...</p>
<a id="md:features" class="tsd-anchor"></a><h2><a href="#md:features">Features</a></h2><ul>
<li>Typescript support</li>
<li>Can run inference directly on browser (using <a href="https://emscripten.org/docs/porting/simd.html">WebAssembly SIMD</a>), no backend or GPU is needed!</li>
<li>No runtime dependency (see <a href="./package.json">package.json</a>)</li>
<li>High-level API: completions, embeddings</li>
<li>Low-level API: (de)tokenize, KV cache control, sampling control,...</li>
<li>Ability to split the model into smaller files and load them in parallel (same as <code>split</code> and <code>cat</code>)</li>
<li>Auto switch between single-thread and multi-thread build based on browser support</li>
<li>Inference is done inside a worker, does not block UI render</li>
<li>Pre-built npm package <a href="https://www.npmjs.com/package/@wllama/wllama">@wllama/wllama</a></li>
</ul>
<p>Limitations:</p>
<ul>
<li>To enable multi-thread, you must add <code>Cross-Origin-Embedder-Policy</code> and <code>Cross-Origin-Opener-Policy</code> headers. See <a href="https://github.com/ffmpegwasm/ffmpeg.wasm/issues/106#issuecomment-913450724">this discussion</a> for more details.</li>
<li>No WebGL support, but maybe possible in the future</li>
<li>Max model size is 2GB, due to <a href="https://stackoverflow.com/questions/17823225/do-arraybuffers-have-a-maximum-length">size restriction of ArrayBuffer</a></li>
</ul>
<a id="md:demo-and-documentations" class="tsd-anchor"></a><h2><a href="#md:demo-and-documentations">Demo and documentations</a></h2><p><strong>Documentation:</strong> <a href="https://ngxson.github.io/wllama/docs/">https://ngxson.github.io/wllama/docs/</a></p>
<p>Demo:</p>
<ul>
<li>Basic usages with completions and embeddings: <a href="https://ngxson.github.io/wllama/examples/basic/">https://ngxson.github.io/wllama/examples/basic/</a></li>
<li>Advanced example using low-level API: <a href="https://ngxson.github.io/wllama/examples/advanced/">https://ngxson.github.io/wllama/examples/advanced/</a></li>
</ul>
<a id="md:how-to-use" class="tsd-anchor"></a><h2><a href="#md:how-to-use">How to use</a></h2><a id="md:use-wllama-inside-react-typescript-project" class="tsd-anchor"></a><h3><a href="#md:use-wllama-inside-react-typescript-project">Use Wllama inside React Typescript project</a></h3><p>Install it:</p>
<pre><code class="language-bash"><span class="hl-0">npm</span><span class="hl-1"> </span><span class="hl-2">i</span><span class="hl-1"> </span><span class="hl-2">@wllama/wllama</span>
</code><button>Copy</button></pre>
<p>For complete code, see <a href="./examples/reactjs">examples/reactjs</a></p>
<p>NOTE: this example only covers completions usage. For embeddings, please see <a href="./examples/basic/index.html">examples/basic/index.html</a></p>
<a id="md:simple-usage-with-es6-module" class="tsd-anchor"></a><h3><a href="#md:simple-usage-with-es6-module">Simple usage with ES6 module</a></h3><p>For complete code, see <a href="./examples/basic/index.html">examples/basic/index.html</a></p>
<pre><code class="language-javascript"><span class="hl-3">import</span><span class="hl-1"> { </span><span class="hl-4">Wllama</span><span class="hl-1"> } </span><span class="hl-3">from</span><span class="hl-1"> </span><span class="hl-2">&#39;./esm/index.js&#39;</span><span class="hl-1">;</span><br/><br/><span class="hl-1">(</span><span class="hl-5">async</span><span class="hl-1"> () </span><span class="hl-5">=&gt;</span><span class="hl-1"> {</span><br/><span class="hl-1">  </span><span class="hl-5">const</span><span class="hl-1"> </span><span class="hl-6">CONFIG_PATHS</span><span class="hl-1"> = {</span><br/><span class="hl-1">    </span><span class="hl-2">&#39;single-thread/wllama.wasm&#39;</span><span class="hl-4">     :</span><span class="hl-1"> </span><span class="hl-2">&#39;./esm/single-thread/wllama.wasm&#39;</span><span class="hl-1">,</span><br/><span class="hl-1">    </span><span class="hl-2">&#39;multi-thread/wllama.wasm&#39;</span><span class="hl-4">      :</span><span class="hl-1"> </span><span class="hl-2">&#39;./esm/multi-thread/wllama.wasm&#39;</span><span class="hl-1">,</span><br/><span class="hl-1">    </span><span class="hl-2">&#39;multi-thread/wllama.worker.mjs&#39;</span><span class="hl-4">:</span><span class="hl-1"> </span><span class="hl-2">&#39;./esm/multi-thread/wllama.worker.mjs&#39;</span><span class="hl-1">,</span><br/><span class="hl-1">  };</span><br/><span class="hl-1">  </span><span class="hl-7">// Automatically switch between single-thread and multi-thread version based on browser support</span><br/><span class="hl-1">  </span><span class="hl-7">// If you want to enforce single-thread, add { &quot;n_threads&quot;: 1 } to LoadModelConfig</span><br/><span class="hl-1">  </span><span class="hl-5">const</span><span class="hl-1"> </span><span class="hl-6">wllama</span><span class="hl-1"> = </span><span class="hl-5">new</span><span class="hl-1"> </span><span class="hl-0">Wllama</span><span class="hl-1">(</span><span class="hl-6">CONFIG_PATHS</span><span class="hl-1">);</span><br/><span class="hl-1">  </span><span class="hl-3">await</span><span class="hl-1"> </span><span class="hl-4">wllama</span><span class="hl-1">.</span><span class="hl-0">loadModelFromUrl</span><span class="hl-1">(</span><span class="hl-2">&#39;https://huggingface.co/ggml-org/models/resolve/main/tinyllamas/stories260K.gguf&#39;</span><span class="hl-1">, {});</span><br/><span class="hl-1">  </span><span class="hl-5">const</span><span class="hl-1"> </span><span class="hl-6">outputText</span><span class="hl-1"> = </span><span class="hl-3">await</span><span class="hl-1"> </span><span class="hl-4">wllama</span><span class="hl-1">.</span><span class="hl-0">createCompletion</span><span class="hl-1">(</span><span class="hl-4">elemInput</span><span class="hl-1">.</span><span class="hl-4">value</span><span class="hl-1">, {</span><br/><span class="hl-1">    </span><span class="hl-4">nPredict:</span><span class="hl-1"> </span><span class="hl-8">50</span><span class="hl-1">,</span><br/><span class="hl-1">    </span><span class="hl-4">sampling:</span><span class="hl-1"> {</span><br/><span class="hl-1">      </span><span class="hl-4">temp:</span><span class="hl-1"> </span><span class="hl-8">0.5</span><span class="hl-1">,</span><br/><span class="hl-1">      </span><span class="hl-4">top_k:</span><span class="hl-1"> </span><span class="hl-8">40</span><span class="hl-1">,</span><br/><span class="hl-1">      </span><span class="hl-4">top_p:</span><span class="hl-1"> </span><span class="hl-8">0.9</span><span class="hl-1">,</span><br/><span class="hl-1">    },</span><br/><span class="hl-1">  });</span><br/><span class="hl-1">  </span><span class="hl-4">console</span><span class="hl-1">.</span><span class="hl-0">log</span><span class="hl-1">(</span><span class="hl-4">outputText</span><span class="hl-1">);</span><br/><span class="hl-1">})();</span>
</code><button>Copy</button></pre>
<a id="md:how-to-build" class="tsd-anchor"></a><h2><a href="#md:how-to-build">How to build</a></h2><p>This repository already come with pre-built binary. But if you want to build it yourself, you can use the commands below:</p>
<pre><code class="language-shell"><span class="hl-7"># Require having docker compose installed</span><br/><span class="hl-7"># Firstly, build llama.cpp into wasm</span><br/><span class="hl-0">npm</span><span class="hl-1"> </span><span class="hl-2">run</span><span class="hl-1"> </span><span class="hl-2">build:wasm</span><br/><span class="hl-7"># (Optionally) Build ES6 module</span><br/><span class="hl-0">npm</span><span class="hl-1"> </span><span class="hl-2">run</span><span class="hl-1"> </span><span class="hl-2">build</span>
</code><button>Copy</button></pre>
<a id="md:todo" class="tsd-anchor"></a><h2><a href="#md:todo">TODO</a></h2><p>Short term:</p>
<ul>
<li>Guide: How to split gguf file into smaller one?</li>
<li>Add a more pratical embedding example (using a better model)</li>
<li>Maybe doing a full RAG-in-browser example using tinyllama?</li>
</ul>
<p>Long term:</p>
<ul>
<li>Support GPU inference via WebGL</li>
<li>Support multi-sequences: knowing the resource limitation when using WASM, I don&#39;t think having multi-sequences is a good idea</li>
<li>Multi-modal: Waiting for refactoring LLaVA implementation from llama.cpp</li>
</ul>
</div></div><div class="col-sidebar"><div class="page-menu"><div class="tsd-navigation settings"><details class="tsd-index-accordion"><summary class="tsd-accordion-summary"><h3><svg width="20" height="20" viewBox="0 0 24 24" fill="none"><use href="assets/icons.svg#icon-chevronDown"></use></svg>Settings</h3></summary><div class="tsd-accordion-details"><div class="tsd-filter-visibility"><h4 class="uppercase">Member Visibility</h4><form><ul id="tsd-filter-options"><li class="tsd-filter-item"><label class="tsd-filter-input"><input type="checkbox" id="tsd-filter-protected" name="protected"/><svg width="32" height="32" viewBox="0 0 32 32" aria-hidden="true"><rect class="tsd-checkbox-background" width="30" height="30" x="1" y="1" rx="6" fill="none"></rect><path class="tsd-checkbox-checkmark" d="M8.35422 16.8214L13.2143 21.75L24.6458 10.25" stroke="none" stroke-width="3.5" stroke-linejoin="round" fill="none"></path></svg><span>Protected</span></label></li><li class="tsd-filter-item"><label class="tsd-filter-input"><input type="checkbox" id="tsd-filter-private" name="private"/><svg width="32" height="32" viewBox="0 0 32 32" aria-hidden="true"><rect class="tsd-checkbox-background" width="30" height="30" x="1" y="1" rx="6" fill="none"></rect><path class="tsd-checkbox-checkmark" d="M8.35422 16.8214L13.2143 21.75L24.6458 10.25" stroke="none" stroke-width="3.5" stroke-linejoin="round" fill="none"></path></svg><span>Private</span></label></li><li class="tsd-filter-item"><label class="tsd-filter-input"><input type="checkbox" id="tsd-filter-inherited" name="inherited" checked/><svg width="32" height="32" viewBox="0 0 32 32" aria-hidden="true"><rect class="tsd-checkbox-background" width="30" height="30" x="1" y="1" rx="6" fill="none"></rect><path class="tsd-checkbox-checkmark" d="M8.35422 16.8214L13.2143 21.75L24.6458 10.25" stroke="none" stroke-width="3.5" stroke-linejoin="round" fill="none"></path></svg><span>Inherited</span></label></li><li class="tsd-filter-item"><label class="tsd-filter-input"><input type="checkbox" id="tsd-filter-external" name="external"/><svg width="32" height="32" viewBox="0 0 32 32" aria-hidden="true"><rect class="tsd-checkbox-background" width="30" height="30" x="1" y="1" rx="6" fill="none"></rect><path class="tsd-checkbox-checkmark" d="M8.35422 16.8214L13.2143 21.75L24.6458 10.25" stroke="none" stroke-width="3.5" stroke-linejoin="round" fill="none"></path></svg><span>External</span></label></li></ul></form></div><div class="tsd-theme-toggle"><h4 class="uppercase">Theme</h4><select id="tsd-theme"><option value="os">OS</option><option value="light">Light</option><option value="dark">Dark</option></select></div></div></details></div><details open class="tsd-index-accordion tsd-page-navigation"><summary class="tsd-accordion-summary"><h3><svg width="20" height="20" viewBox="0 0 24 24" fill="none"><use href="assets/icons.svg#icon-chevronDown"></use></svg>On This Page</h3></summary><div class="tsd-accordion-details"><a href="#md:wllama---wasm-binding-for-llamacpp"><span>wllama -<wbr/> <wbr/>Wasm binding for llama.cpp</span></a><ul><li><a href="#md:features"><span>Features</span></a></li><li><a href="#md:demo-and-documentations"><span>Demo and documentations</span></a></li><li><a href="#md:how-to-use"><span>How to use</span></a></li><li><ul><li><a href="#md:use-wllama-inside-react-typescript-project"><span>Use <wbr/>Wllama inside <wbr/>React <wbr/>Typescript project</span></a></li><li><a href="#md:simple-usage-with-es6-module"><span>Simple usage with ES6 module</span></a></li></ul></li><li><a href="#md:how-to-build"><span>How to build</span></a></li><li><a href="#md:todo"><span>TODO</span></a></li></ul></div></details></div><div class="site-menu"><nav class="tsd-navigation"><a href="modules.html" class="current"><svg class="tsd-kind-icon" viewBox="0 0 24 24"><use href="assets/icons.svg#icon-1"></use></svg><span>@wllama/wllama</span></a><ul class="tsd-small-nested-navigation" id="tsd-nav-container" data-base="."><li>Loading...</li></ul></nav></div></div></div><div class="tsd-generator"><p>Generated using <a href="https://typedoc.org/" target="_blank">TypeDoc</a></p></div><div class="overlay"></div></body></html>